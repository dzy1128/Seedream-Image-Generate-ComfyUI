import os
import requests
import torch
import numpy as np
from PIL import Image
import io
import time
import folder_paths
from volcenginesdkarkruntime import Ark
from volcenginesdkarkruntime.types.images.images import SequentialImageGenerationOptions

class SeedreamImageGenerate:
    """
    A ComfyUI node for generating images using Volcengine Seedream API
    """
    
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "prompt": ("STRING", {
                    "multiline": True,
                    "default": "",
                    "placeholder": "Enter your image generation prompt here..."
                }),
                "model": (["doubao-seedream-4-0-250828", "doubao-seedream-4-5-251128"], {
                    "default": "doubao-seedream-4-0-250828"
                }),
                "aspect_ratio": (["1:1", "2:3", "3:2", "4:3", "3:4", "16:9", "9:16", "21:9", "2K", "3K", "3.5K", "4K"], {
                    "default": "1:1"
                }),
                "sequential_image_generation": (["auto", "enabled", "disabled"], {
                    "default": "auto",
                    "tooltip": "é¡ºåºç”Ÿæˆæ¨¡å¼ï¼šauto=è‡ªåŠ¨ï¼Œenabled=å¯ç”¨ï¼Œdisabled=ç¦ç”¨"
                }),
                "max_images": ("INT", {
                    "default": 1,
                    "min": 1,
                    "max": 10,
                    "step": 1,
                    "tooltip": "sequential_image_generation_options.max_images - æœ€å¤§ç”Ÿæˆå›¾ç‰‡æ•°é‡ï¼ˆç”¨äºé¡ºåºç”Ÿæˆï¼‰"
                }),
                "response_format": (["url", "b64_json"], {
                    "default": "url"
                }),
                "watermark": ("BOOLEAN", {
                    "default": False
                }),
                "stream": ("BOOLEAN", {
                    "default": False,
                    "tooltip": "æµå¼ä¼ è¾“æ¨¡å¼ - å¯ç”¨åä¸max_imagesé…åˆå¯ç”Ÿæˆå¤šå¼ å›¾ç‰‡"
                }),
                "base_url": ("STRING", {
                    "default": "https://ark.cn-beijing.volces.com/api/v3"
                }),
                "use_local_images": ("BOOLEAN", {
                    "default": True,
                    "tooltip": "ä½¿ç”¨æœ¬åœ°å›¾åƒï¼ˆBase64æ ¼å¼ï¼Œå®˜æ–¹æ”¯æŒï¼‰"
                }),
                "seed": ("INT", {
                    "default": 0,
                    "min": 0,
                    "max": 18446744073709551615,  # æ”¯æŒ64ä½æ•´æ•°
                    "step": 1
                }),
                "enable_auto_retry": ("BOOLEAN", {
                    "default": True,
                    "tooltip": "å¯ç”¨è‡ªåŠ¨é‡è¯•æœºåˆ¶ï¼Œå¤„ç†äº‘ç«¯å·¥ä½œæµçš„å¼‚æ­¥æ‰§è¡Œé—®é¢˜"
                }),
            },
            "optional": {
                "image1": ("IMAGE",),
                "image2": ("IMAGE",),
                "image3": ("IMAGE",),
                "image4": ("IMAGE",),
                "image5": ("IMAGE",)
            }
        }
    
    RETURN_TYPES = ("IMAGE", "STRING")
    RETURN_NAMES = ("images", "text")
    OUTPUT_IS_LIST = (True, False)
    FUNCTION = "generate_images"
    CATEGORY = "image/generation"
    
    def __init__(self):
        self.client = None
        self.max_retries = 3
        self.retry_delay = 1.0  # ç§’
    
    def tensor_to_pil(self, tensor):
        """Convert ComfyUI tensor to PIL Image"""
        # Convert tensor to numpy array
        i = 255. * tensor.cpu().numpy()
        img = Image.fromarray(np.clip(i, 0, 255).astype(np.uint8))
        return img
    
    def pil_to_tensor(self, pil_image):
        """Convert PIL Image to ComfyUI tensor"""
        img = np.array(pil_image).astype(np.float32) / 255.0
        return torch.from_numpy(img)[None,]
    
    def validate_input_data(self, image1, retry_count=0):
        """
        éªŒè¯è¾“å…¥æ•°æ®çš„å®Œæ•´æ€§ï¼Œæ”¯æŒé‡è¯•æœºåˆ¶å¤„ç†äº‘ç«¯å·¥ä½œæµçš„å¼‚æ­¥ç‰¹æ€§
        """
        max_retries = 3
        
        # åŸºæœ¬éªŒè¯
        if image1 is None:
            if retry_count < max_retries:
                print(f"è¾“å…¥éªŒè¯å¤±è´¥ (å°è¯• {retry_count + 1}/{max_retries + 1}): image1 ä¸º Noneï¼Œç­‰å¾… {self.retry_delay} ç§’åé‡è¯•...")
                time.sleep(self.retry_delay)
                return False, "image1_none"
            else:
                raise ValueError("image1 å‚æ•°æ˜¯å¿…éœ€çš„ï¼Œè¯·ç¡®ä¿ä¸Šæ¸¸èŠ‚ç‚¹å·²æ­£ç¡®è¿æ¥å¹¶æ‰§è¡Œå®Œæˆ")
        
        # æ£€æŸ¥tensorç±»å‹
        if not isinstance(image1, torch.Tensor):
            if retry_count < max_retries:
                print(f"è¾“å…¥éªŒè¯å¤±è´¥ (å°è¯• {retry_count + 1}/{max_retries + 1}): image1 ç±»å‹é”™è¯¯ {type(image1)}ï¼Œç­‰å¾… {self.retry_delay} ç§’åé‡è¯•...")
                time.sleep(self.retry_delay)
                return False, "image1_type"
            else:
                raise ValueError(f"image1 å¿…é¡»æ˜¯torch.Tensorç±»å‹ï¼Œå½“å‰ç±»å‹: {type(image1)}")
        
        # æ£€æŸ¥tensorå½¢çŠ¶
        if len(image1.shape) < 3:
            if retry_count < max_retries:
                print(f"è¾“å…¥éªŒè¯å¤±è´¥ (å°è¯• {retry_count + 1}/{max_retries + 1}): image1 å½¢çŠ¶æ— æ•ˆ {image1.shape}ï¼Œç­‰å¾… {self.retry_delay} ç§’åé‡è¯•...")
                time.sleep(self.retry_delay)
                return False, "image1_shape"
            else:
                raise ValueError(f"image1 tensorå½¢çŠ¶æ— æ•ˆ: {image1.shape}ï¼ŒæœŸæœ›è‡³å°‘3ç»´")
        
        # æ£€æŸ¥tensoræ•°æ®è´¨é‡ - é¿å…å…¨é›¶æˆ–æ— æ•ˆæ•°æ®
        if torch.all(image1 == 0) or torch.isnan(image1).any():
            if retry_count < max_retries:
                print(f"è¾“å…¥éªŒè¯å¤±è´¥ (å°è¯• {retry_count + 1}/{max_retries + 1}): image1 æ•°æ®è´¨é‡é—®é¢˜ï¼ˆå…¨é›¶æˆ–åŒ…å«NaNï¼‰ï¼Œç­‰å¾… {self.retry_delay} ç§’åé‡è¯•...")
                time.sleep(self.retry_delay)
                return False, "image1_quality"
            else:
                print("è­¦å‘Š: image1 åŒ…å«å¼‚å¸¸æ•°æ®ï¼Œä½†å°†ç»§ç»­æ‰§è¡Œ...")
        
        print(f"âœ… è¾“å…¥éªŒè¯é€šè¿‡: image1 å½¢çŠ¶ {image1.shape}, æ•°æ®ç±»å‹ {image1.dtype}")
        return True, "success"
    
    def convert_image_to_supported_format(self, pil_image, use_local_images=False):
        """
        å°†æœ¬åœ°å›¾åƒè½¬æ¢ä¸ºAPIæ”¯æŒçš„æ ¼å¼
        æ ¹æ®å®˜æ–¹æ–‡æ¡£ï¼šæ”¯æŒBase64ç¼–ç æ ¼å¼ data:image/<å›¾ç‰‡æ ¼å¼>;base64,<Base64ç¼–ç >
        """
        try:
            if use_local_images:
                # ä½¿ç”¨å®˜æ–¹æ”¯æŒçš„Base64æ ¼å¼
                try:
                    import base64
                    
                    # ç¡®ä¿å›¾åƒæ˜¯RGBæ ¼å¼
                    if pil_image.mode != 'RGB':
                        pil_image = pil_image.convert('RGB')
                    
                    # ä¿å­˜ä¸ºPNGæ ¼å¼åˆ°å†…å­˜
                    buffered = io.BytesIO()
                    pil_image.save(buffered, format="PNG")
                    img_bytes = buffered.getvalue()
                    
                    # ç¼–ç ä¸ºBase64
                    img_base64 = base64.b64encode(img_bytes).decode('utf-8')
                    
                    # æŒ‰ç…§å®˜æ–¹æ–‡æ¡£æ ¼å¼ï¼šdata:image/png;base64,<base64_image>
                    data_url = f"data:image/png;base64,{img_base64}"
                    
                    return data_url
                    
                except Exception as e:
                    # è½¬æ¢å¤±è´¥æ—¶å›é€€åˆ°ç¤ºä¾‹å›¾åƒ
                    return self._get_example_image_url()
            
            # é»˜è®¤æ¨¡å¼ï¼šä½¿ç”¨å®˜æ–¹ç¤ºä¾‹å›¾åƒURL
            return self._get_example_image_url()
            
        except Exception as e:
            return self._get_example_image_url()
    
    def _get_example_image_url(self):
        """è·å–ç¤ºä¾‹å›¾åƒURL"""
        example_urls = [
            "https://ark-project.tos-cn-beijing.volces.com/doc_image/seedream4_imagesToimages_1.png",
            "https://ark-project.tos-cn-beijing.volces.com/doc_image/seedream4_imagesToimages_2.png"
        ]
        
        import random
        return random.choice(example_urls)
    
    def aspect_ratio_to_size(self, aspect_ratio):
        """Convert aspect ratio to size parameter"""
        ratio_map = {
            "1:1": "2048x2048",
            "4:3": "2304x1728", 
            "3:4": "1728x2304",
            "16:9": "2560x1440",
            "9:16": "1440x2560",
            "3:2": "2496x1664",
            "2:3": "1664x2496",
            #"2:3": "1040x1560",
            "21:9": "3024x1296",
            "2K": "2K",
            "3K": "2133x3200",
            "3.5K": "2933x4400",
            "4K": "4K"
        }
        return ratio_map.get(aspect_ratio, "2048x2048")
    
    def download_image_from_url(self, url):
        """Download image from URL and convert to tensor"""
        try:
            response = requests.get(url)
            response.raise_for_status()
            image = Image.open(io.BytesIO(response.content))
            if image.mode != 'RGB':
                image = image.convert('RGB')
            return self.pil_to_tensor(image)
        except Exception as e:
            # Return a black placeholder image
            placeholder = Image.new('RGB', (512, 512), color='black')
            return self.pil_to_tensor(placeholder)
    
    def initialize_client(self, base_url):
        """Initialize the Ark client"""
        api_key = os.environ.get("ARK_API_KEY")
        
        if not api_key:
            raise ValueError("API Key is required. Please set ARK_API_KEY environment variable.")
        
        self.client = Ark(
            base_url=base_url,
            api_key=api_key.strip()
        )
    
    def generate_images(self, prompt, model, aspect_ratio, sequential_image_generation, 
                       max_images, response_format, watermark, stream, base_url, use_local_images, seed, enable_auto_retry,
                       image1=None, image2=None, image3=None, image4=None, image5=None):
        
        # æ ¹æ®ç”¨æˆ·è®¾ç½®å†³å®šæ˜¯å¦ä½¿ç”¨é‡è¯•æœºåˆ¶
        max_attempts = self.max_retries + 1 if enable_auto_retry else 1
        
        for retry_count in range(max_attempts):
            try:
                # ä½¿ç”¨æ™ºèƒ½éªŒè¯æœºåˆ¶éªŒè¯è¾“å…¥æ•°æ®ï¼ˆå¦‚æœimage1å­˜åœ¨çš„è¯ï¼‰
                if image1 is not None:
                    is_valid, error_type = self.validate_input_data(image1, retry_count)
                    
                    if not is_valid:
                        if enable_auto_retry and retry_count < self.max_retries:
                            # å¦‚æœå¯ç”¨é‡è¯•ä¸”è¿˜æœ‰é‡è¯•æœºä¼šï¼Œç»§ç»­ä¸‹ä¸€æ¬¡å¾ªç¯
                            continue
                        else:
                            # æœ€ç»ˆå¤±è´¥ï¼Œè®©validate_input_dataæŠ›å‡ºå¼‚å¸¸
                            self.validate_input_data(image1, retry_count)
                
                # éªŒè¯é€šè¿‡ï¼Œç»§ç»­æ‰§è¡Œ
                if retry_count > 0 and enable_auto_retry:
                    print(f"âœ… é‡è¯•æˆåŠŸï¼å¼€å§‹æ‰§è¡Œå›¾åƒç”Ÿæˆ (å°è¯• {retry_count + 1}/{max_attempts})")
                    print("ğŸ’¡ æç¤ºï¼šå¦‚æœç»å¸¸éœ€è¦é‡è¯•ï¼Œå»ºè®®åœ¨å·¥ä½œæµä¸­æ·»åŠ é€‚å½“çš„å»¶è¿Ÿæˆ–ç¡®ä¿ä¸Šæ¸¸èŠ‚ç‚¹å®Œå…¨æ‰§è¡Œåå†è§¦å‘æ­¤èŠ‚ç‚¹")
                else:
                    print(f"ğŸš€ å¼€å§‹æ‰§è¡Œå›¾åƒç”Ÿæˆ")
                    
                return self._execute_generation(prompt, model, aspect_ratio, sequential_image_generation, 
                                              max_images, response_format, watermark, stream, base_url, use_local_images, seed, enable_auto_retry,
                                              image1, image2, image3, image4, image5)
                
            except Exception as e:
                if enable_auto_retry and retry_count < self.max_retries:
                    print(f"æ‰§è¡Œå¤±è´¥ (å°è¯• {retry_count + 1}/{max_attempts}): {str(e)}")
                    print(f"ç­‰å¾… {self.retry_delay} ç§’åé‡è¯•...")
                    time.sleep(self.retry_delay)
                    continue
                else:
                    # æœ€åä¸€æ¬¡é‡è¯•ä¹Ÿå¤±è´¥äº†ï¼Œæˆ–è€…æ²¡æœ‰å¯ç”¨é‡è¯•ï¼ŒæŠ›å‡ºå¼‚å¸¸
                    raise e
    
    def _execute_generation(self, prompt, model, aspect_ratio, sequential_image_generation, 
                           max_images, response_format, watermark, stream, base_url, use_local_images, seed, enable_auto_retry,
                           image1=None, image2=None, image3=None, image4=None, image5=None):
        """
        å®é™…æ‰§è¡Œå›¾åƒç”Ÿæˆçš„æ ¸å¿ƒé€»è¾‘
        """
        try:
            
            # æ ‡å‡†åŒ–seedå‚æ•° - å°†å¤§çš„seedå€¼æ˜ å°„åˆ°æœ‰æ•ˆèŒƒå›´å†…
            normalized_seed = seed
            if seed > 2147483647:
                # ä½¿ç”¨æ¨¡è¿ç®—å°†å¤§seedå€¼æ˜ å°„åˆ°æœ‰æ•ˆèŒƒå›´
                normalized_seed = seed % 2147483647
                print(f"åŸå§‹seedå€¼ {seed} è¢«æ ‡å‡†åŒ–ä¸º {normalized_seed}")
            
            # Initialize client
            self.initialize_client(base_url)
            
            # Note: normalized_seed parameter is available for workflow tracking but not sent to the API
            # The Volcengine Seedream API doesn't currently support seed parameter
            
            # Collect input images - ç°åœ¨æ‰€æœ‰å›¾ç‰‡éƒ½æ˜¯å¯é€‰çš„ï¼Œå¯ä»¥ä¸æä¾›å›¾ç‰‡
            input_images = []
            if image1 is not None:
                input_images.append(image1)
            if image2 is not None:
                input_images.append(image2)
            if image3 is not None:
                input_images.append(image3)
            if image4 is not None:
                input_images.append(image4)
            if image5 is not None:
                input_images.append(image5)
            
            # Convert input images to URLs
            image_urls = []
            
            for i, img_tensor in enumerate(input_images):
                # Convert tensor to PIL
                pil_img = self.tensor_to_pil(img_tensor.squeeze(0))
                # è½¬æ¢ä¸ºAPIæ”¯æŒçš„æ ¼å¼
                url = self.convert_image_to_supported_format(pil_img, use_local_images)
                image_urls.append(url)
                
            # Convert aspect ratio to size
            size = self.aspect_ratio_to_size(aspect_ratio)
            
            # Prepare generation options
            # ä½¿ç”¨SDKçš„SequentialImageGenerationOptionsç±»
            # å¯¹åº”å®˜æ–¹API: {"max_images": int}
            generation_options = SequentialImageGenerationOptions(max_images=max_images)
            print(f"ğŸ”„ é¡ºåºç”Ÿæˆé€‰é¡¹: max_images={max_images}")
            
            # Generate images - æ ¹æ®æ˜¯å¦æœ‰å›¾ç‰‡è¾“å…¥æ¥å†³å®šå‚æ•°
            generate_params = {
                "model": model,
                "prompt": prompt,
                "size": size,
                "sequential_image_generation": sequential_image_generation,
                "sequential_image_generation_options": generation_options,
                "response_format": response_format,
                "watermark": watermark,
                "stream": stream
            }
            
            # åªæœ‰åœ¨æœ‰å›¾ç‰‡è¾“å…¥æ—¶æ‰æ·»åŠ imageå‚æ•°
            if image_urls:
                generate_params["image"] = image_urls
                print(f"ğŸ“¸ ä½¿ç”¨ {len(image_urls)} å¼ è¾“å…¥å›¾ç‰‡è¿›è¡Œç”Ÿæˆ")
            else:
                print(f"ğŸ¨ æ–‡ç”Ÿå›¾æ¨¡å¼ï¼šä»…ä½¿ç”¨æç¤ºè¯ç”Ÿæˆå›¾ç‰‡ï¼ˆæ— è¾“å…¥å›¾ç‰‡ï¼‰")
            
            print(f"ğŸ“¤ å‘é€APIè¯·æ±‚")
            print(f"   æ¨¡å‹: {model}")
            print(f"   é¡ºåºç”Ÿæˆ: {sequential_image_generation}")
            print(f"   é¡ºåºç”Ÿæˆé€‰é¡¹: max_images={max_images}")
            print(f"   stream: {stream}")
            print(f"   å›¾ç‰‡è¾“å…¥æ•°: {len(image_urls) if image_urls else 0}")
            
            # æ‰“å°APIå‚æ•°æ‘˜è¦ï¼ˆä¸æ‰“å°å®Œæ•´å‚æ•°ï¼Œé¿å…åºåˆ—åŒ–é—®é¢˜ï¼‰
            print(f"ğŸ“‹ APIå‚æ•°æ‘˜è¦:")
            print(f"   - model: {model}")
            print(f"   - size: {size}")
            print(f"   - response_format: {response_format}")
            print(f"   - watermark: {watermark}")
            print(f"   - stream: {stream}")
            print(f"   - æœ‰å›¾ç‰‡è¾“å…¥: {len(image_urls) > 0 if image_urls else False}")
            
            images_response = self.client.images.generate(**generate_params)
            
            # å¤„ç†æµå¼å“åº”
            all_image_data = []
            if stream:
                print(f"ğŸŒŠ æµå¼å“åº”æ¨¡å¼ï¼Œæ­£åœ¨æ”¶é›†æ‰€æœ‰å›¾ç‰‡...")
                try:
                    # æµå¼å“åº”è¿”å›çš„æ˜¯è¿­ä»£å™¨ï¼Œéœ€è¦éå†æ”¶é›†æ‰€æœ‰å›¾ç‰‡
                    chunk_count = 0
                    for chunk in images_response:
                        chunk_count += 1
                        print(f"   ğŸ“¦ æ”¶åˆ°ç¬¬ {chunk_count} ä¸ªchunk, ç±»å‹: {type(chunk)}")
                        
                        if hasattr(chunk, 'data'):
                            print(f"   âœ“ Chunkæœ‰dataå±æ€§ï¼Œæ•°æ®é¡¹æ•°: {len(chunk.data)}")
                            for img_data in chunk.data:
                                # éªŒè¯å›¾ç‰‡æ•°æ®æœ‰æ•ˆæ€§
                                has_url = hasattr(img_data, 'url') and img_data.url is not None
                                has_b64 = hasattr(img_data, 'b64_json') and img_data.b64_json is not None
                                
                                if has_url or has_b64:
                                    all_image_data.append(img_data)
                                    size_info = img_data.size if hasattr(img_data, 'size') else 'unknown'
                                    url_preview = img_data.url[:50] + '...' if has_url and len(img_data.url) > 50 else (img_data.url if has_url else 'b64_json')
                                    print(f"   âœ… æ”¶åˆ°ç¬¬ {len(all_image_data)} å¼ æœ‰æ•ˆå›¾ç‰‡: {size_info}, URL: {url_preview}")
                                else:
                                    print(f"   âš ï¸ è·³è¿‡æ— æ•ˆå›¾ç‰‡æ•°æ®: url={getattr(img_data, 'url', None)}, b64_json={'å­˜åœ¨' if has_b64 else 'ä¸å­˜åœ¨'}")
                        else:
                            print(f"   âš ï¸ Chunkæ²¡æœ‰dataå±æ€§")
                            # å¯èƒ½chunkæœ¬èº«å°±æ˜¯image data
                            has_url = hasattr(chunk, 'url') and chunk.url is not None
                            has_b64 = hasattr(chunk, 'b64_json') and chunk.b64_json is not None
                            
                            if has_url or has_b64:
                                all_image_data.append(chunk)
                                print(f"   âœ… ç›´æ¥æ”¶é›†chunkä¸ºå›¾ç‰‡: {len(all_image_data)}")
                    
                    print(f"ğŸ“Š æµå¼å“åº”å®Œæˆï¼Œå…±æ”¶åˆ° {chunk_count} ä¸ªchunkï¼Œæ”¶é›† {len(all_image_data)} å¼ æœ‰æ•ˆå›¾ç‰‡")
                except Exception as e:
                    print(f"âŒ å¤„ç†æµå¼å“åº”æ—¶å‡ºé”™: {type(e).__name__}: {e}")
                    import traceback
                    traceback.print_exc()
                    raise
            else:
                # éæµå¼å“åº”ï¼Œç›´æ¥ä½¿ç”¨data
                print(f"ğŸ“¦ éæµå¼å“åº”æ¨¡å¼")
                print(f"   å“åº”ç±»å‹: {type(images_response)}")
                
                if hasattr(images_response, 'data'):
                    # è¿‡æ»¤æœ‰æ•ˆå›¾ç‰‡æ•°æ®
                    for img_data in images_response.data:
                        has_url = hasattr(img_data, 'url') and img_data.url is not None
                        has_b64 = hasattr(img_data, 'b64_json') and img_data.b64_json is not None
                        if has_url or has_b64:
                            all_image_data.append(img_data)
                    print(f"ğŸ“Š éæµå¼å“åº”ï¼Œè¿”å› {len(all_image_data)} å¼ æœ‰æ•ˆå›¾ç‰‡")
                else:
                    print(f"âš ï¸ å“åº”æ²¡æœ‰dataå±æ€§")
            
            if not all_image_data:
                error_detail = f"APIæœªè¿”å›ä»»ä½•å›¾ç‰‡æ•°æ®\n"
                error_detail += f"  - streamæ¨¡å¼: {stream}\n"
                if stream:
                    error_detail += f"  - æ”¶åˆ°chunkæ•°: {chunk_count}\n"
                error_detail += f"  - å“åº”ç±»å‹: {type(images_response)}\n"
                error_detail += f"\nğŸ’¡ å¯èƒ½çš„åŸå› :\n"
                error_detail += f"  1. APIè¿”å›æ ¼å¼ä¸é¢„æœŸä¸ç¬¦\n"
                error_detail += f"  2. æµå¼å“åº”å¤„ç†æ–¹å¼éœ€è¦è°ƒæ•´\n"
                error_detail += f"  3. APIå‚æ•°é…ç½®é—®é¢˜\n"
                error_detail += f"\nè¯·æŸ¥çœ‹ä¸Šæ–¹çš„è¯¦ç»†è°ƒè¯•æ—¥å¿—ä»¥ç¡®å®šå…·ä½“åŸå› "
                raise ValueError(error_detail)
            
            # Process generated images and collect information
            output_tensors = []
            result_info = []
            
            # Collect basic generation info
            result_info.append(f"ğŸ¨ ç”Ÿæˆä¿¡æ¯:")
            result_info.append(f"ğŸ“ æç¤ºè¯: {prompt}")
            result_info.append(f"ğŸ”§ æ¨¡å‹: {model}")
            result_info.append(f"ğŸ“ å®½é«˜æ¯”: {aspect_ratio}")
            result_info.append(f"ğŸ”„ é¡ºåºç”Ÿæˆ: {sequential_image_generation}")
            result_info.append(f"   â””â”€ max_images: {max_images} (sequential_image_generation_options)")
            result_info.append(f"ğŸ–¼ï¸ ç”Ÿæˆæ•°é‡: {len(all_image_data)}")
            input_image_count = len([img for img in [image1, image2, image3, image4, image5] if img is not None])
            result_info.append(f"ğŸ“Š è¾“å…¥å›¾åƒ: {input_image_count}å¼ " + (" (æ–‡ç”Ÿå›¾æ¨¡å¼)" if input_image_count == 0 else " (å›¾ç”Ÿå›¾æ¨¡å¼)"))
            result_info.append(f"ğŸ”„ æœ¬åœ°å›¾åƒæ¨¡å¼: {'Base64ç¼–ç ' if use_local_images else 'ç¤ºä¾‹å›¾åƒ'}")
            result_info.append(f"ğŸ² ç§å­å€¼: {normalized_seed}" + (f" (åŸå§‹: {seed})" if seed != normalized_seed else ""))
            result_info.append(f"âš¡ æ‰§è¡ŒçŠ¶æ€: æˆåŠŸ (è‡ªåŠ¨é‡è¯•: {'å¯ç”¨' if enable_auto_retry else 'ç¦ç”¨'})")
            result_info.append("")
            
            for i, image_data in enumerate(all_image_data):
                result_info.append(f"ğŸ“· å›¾åƒ {i+1}:")
                
                # å®‰å…¨è·å–URLå’Œå°ºå¯¸
                url = getattr(image_data, 'url', None)
                size = getattr(image_data, 'size', None)
                
                result_info.append(f"   ğŸ”— URL: {url if url else 'N/A'}")
                result_info.append(f"   ğŸ“ å°ºå¯¸: {size if size else 'N/A'}")
                
                # Add any additional metadata if available
                if hasattr(image_data, 'revised_prompt') and image_data.revised_prompt:
                    result_info.append(f"   âœï¸ ä¿®è®¢æç¤ºè¯: {image_data.revised_prompt}")
                
                if hasattr(image_data, 'finish_reason') and image_data.finish_reason:
                    result_info.append(f"   âœ… å®ŒæˆåŸå› : {image_data.finish_reason}")
                
                if response_format == "url":
                    # Download image from URL
                    if url and url != 'N/A':
                        tensor = self.download_image_from_url(url)
                        output_tensors.append(tensor)
                    else:
                        print(f"âš ï¸ å›¾åƒ {i+1} æ²¡æœ‰æœ‰æ•ˆURLï¼Œè·³è¿‡ä¸‹è½½")
                else:  # b64_json
                    # Handle base64 encoded image
                    if hasattr(image_data, 'b64_json') and image_data.b64_json:
                        import base64
                        image_data_b64 = image_data.b64_json
                        image_bytes = base64.b64decode(image_data_b64)
                        image = Image.open(io.BytesIO(image_bytes))
                        if image.mode != 'RGB':
                            image = image.convert('RGB')
                        tensor = self.pil_to_tensor(image)
                        output_tensors.append(tensor)
                    else:
                        print(f"âš ï¸ å›¾åƒ {i+1} æ²¡æœ‰æœ‰æ•ˆçš„b64_jsonæ•°æ®ï¼Œè·³è¿‡å¤„ç†")
                
                result_info.append("")
            
            # Add generation parameters info
            result_info.append("âš™ï¸ ç”Ÿæˆå‚æ•°:")
            result_info.append(f"   ğŸ¯ å“åº”æ ¼å¼: {response_format}")
            result_info.append(f"   ğŸ’§ æ°´å°: {'æ˜¯' if watermark else 'å¦'}")
            result_info.append(f"   ğŸŒŠ æµå¼ä¼ è¾“: {'æ˜¯' if stream else 'å¦'}")
            result_info.append(f"   ğŸŒ APIåœ°å€: {base_url}")
            
            if not output_tensors:
                # Return a placeholder if no images generated
                placeholder = Image.new('RGB', (512, 512), color='black')
                output_tensors = [self.pil_to_tensor(placeholder)]
                result_info.append("âš ï¸ æœªç”Ÿæˆå›¾åƒï¼Œè¿”å›å ä½ç¬¦")
            
            # Join all info into a single text output
            text_output = "\n".join(result_info)
            
            return (output_tensors, text_output)
            
        except Exception as e:
            error_msg = str(e)
            
            # ç¡®ä¿normalized_seedåœ¨é”™è¯¯å¤„ç†æ—¶ä¹Ÿå¯ç”¨
            normalized_seed = seed
            if seed > 2147483647:
                normalized_seed = seed % 2147483647
            
            # Return a placeholder error image with error text
            error_img = Image.new('RGB', (512, 512), color='red')
            
            # Create detailed error text output with specific troubleshooting
            error_text_parts = [
                "âŒ å›¾åƒç”Ÿæˆå¤±è´¥",
                "",
                f"ğŸ” é”™è¯¯ä¿¡æ¯: {error_msg}",
                ""
            ]
            
            # æ ¹æ®é”™è¯¯ç±»å‹æä¾›å…·ä½“çš„è§£å†³å»ºè®®
            if "image1 å‚æ•°æ˜¯å¿…éœ€çš„" in error_msg or "è‡³å°‘éœ€è¦æä¾›ä¸€å¼ è¾“å…¥å›¾ç‰‡" in error_msg:
                error_text_parts.extend([
                    "ğŸš¨ è¾“å…¥å›¾åƒé—®é¢˜:",
                    "   â€¢ image1 è¾“å…¥æœªè¿æ¥æˆ–ä¸Šæ¸¸èŠ‚ç‚¹æœªæ‰§è¡Œå®Œæˆ",
                    "   â€¢ è¯·ç¡®ä¿LoadImageæˆ–å…¶ä»–å›¾åƒç”ŸæˆèŠ‚ç‚¹å·²æ­£ç¡®è¿æ¥",
                    "   â€¢ å»ºè®®ç­‰å¾…ä¸Šæ¸¸èŠ‚ç‚¹å®Œå…¨æ‰§è¡Œåå†è¿è¡Œæ­¤èŠ‚ç‚¹",
                    "   â€¢ å¦‚æœä½¿ç”¨APIè°ƒç”¨ï¼Œè¯·ç¡®ä¿æ‰€æœ‰ä¾èµ–èŠ‚ç‚¹æŒ‰æ­£ç¡®é¡ºåºæ‰§è¡Œ",
                    ""
                ])
            elif "torch.Tensor" in error_msg:
                error_text_parts.extend([
                    "ğŸš¨ æ•°æ®ç±»å‹é—®é¢˜:",
                    "   â€¢ è¾“å…¥çš„image1ä¸æ˜¯æœ‰æ•ˆçš„å›¾åƒtensor",
                    "   â€¢ è¯·æ£€æŸ¥ä¸Šæ¸¸èŠ‚ç‚¹æ˜¯å¦æ­£ç¡®è¾“å‡ºå›¾åƒæ•°æ®",
                    "   â€¢ ç¡®ä¿è¿æ¥çš„æ˜¯å›¾åƒè¾“å‡ºç«¯å£ï¼Œè€Œä¸æ˜¯å…¶ä»–ç±»å‹çš„è¾“å‡º",
                    ""
                ])
            elif "Invalid image file" in error_msg:
                error_text_parts.extend([
                    "ğŸš¨ å›¾åƒæ–‡ä»¶é—®é¢˜:",
                    "   â€¢ ä¸Šæ¸¸LoadImageèŠ‚ç‚¹çš„å›¾åƒæ–‡ä»¶æ— æ•ˆæˆ–ä¸å­˜åœ¨",
                    "   â€¢ å¸¸è§åŸå› :",
                    "     - æ–‡ä»¶è·¯å¾„æ ¼å¼é”™è¯¯ï¼ˆå¦‚ï¼šclient:syai-prod/...ï¼‰",
                    "     - ä¸´æ—¶æ–‡ä»¶è¿˜æœªç”Ÿæˆå®Œæˆ",
                    "     - æ–‡ä»¶æƒé™æˆ–ç½‘ç»œé—®é¢˜",
                    "     - å·¥ä½œæµæ‰§è¡Œé¡ºåºé—®é¢˜",
                    "   â€¢ è§£å†³æ–¹æ¡ˆ:",
                    "     1. æ£€æŸ¥LoadImageèŠ‚ç‚¹çš„è¾“å…¥è·¯å¾„æ˜¯å¦æ­£ç¡®",
                    "     2. ç¡®ä¿ä½¿ç”¨æœ¬åœ°æ–‡ä»¶è·¯å¾„è€ŒéURLæ ¼å¼",
                    "     3. ç­‰å¾…ä¸Šæ¸¸èŠ‚ç‚¹å®Œå…¨æ‰§è¡Œåå†è¿è¡Œ",
                    "     4. æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨ä¸”å¯è¯»",
                    ""
                ])
            elif "API Key" in error_msg:
                error_text_parts.extend([
                    "ğŸš¨ APIé…ç½®é—®é¢˜:",
                    "   â€¢ ARK_API_KEY ç¯å¢ƒå˜é‡æœªè®¾ç½®æˆ–æ— æ•ˆ",
                    "   â€¢ è¯·è®¾ç½®ç¯å¢ƒå˜é‡: export ARK_API_KEY='your_api_key'",
                    "   â€¢ ç¡®ä¿API Keyæœ‰æ•ˆä¸”æœ‰è¶³å¤Ÿçš„é…é¢",
                    ""
                ])
            elif "bigger than max" in error_msg and "seed" in error_msg:
                error_text_parts.extend([
                    "ğŸš¨ Seedå€¼æº¢å‡ºé—®é¢˜:",
                    f"   â€¢ åŸå§‹seedå€¼ {seed} è¶…è¿‡äº†ç³»ç»Ÿæ”¯æŒçš„æœ€å¤§å€¼",
                    f"   â€¢ å·²è‡ªåŠ¨æ ‡å‡†åŒ–ä¸º: {normalized_seed}",
                    "   â€¢ è¿™ä¸ä¼šå½±å“å›¾åƒç”Ÿæˆè´¨é‡ï¼Œåªæ˜¯ç”¨äºå·¥ä½œæµè·Ÿè¸ª",
                    "   â€¢ å»ºè®®ä½¿ç”¨è¾ƒå°çš„seedå€¼ä»¥é¿å…æ­¤è­¦å‘Š",
                    ""
                ])
            
            error_text_parts.extend([
                f"ğŸ“ æç¤ºè¯: {prompt}",
                f"ğŸ”§ æ¨¡å‹: {model}",
                f"ğŸ“ å®½é«˜æ¯”: {aspect_ratio}",
                f"ğŸ”„ é¡ºåºç”Ÿæˆ: {sequential_image_generation}",
                f"ğŸ–¼ï¸ æœ€å¤§å›¾åƒæ•°: {max_images}",
                f"ğŸŒ APIåœ°å€: {base_url}",
                f"ğŸ§ª ä½¿ç”¨æœ¬åœ°å›¾åƒ: {'æ˜¯' if use_local_images else 'å¦'}",
                f"ğŸ² ç§å­å€¼: {normalized_seed}" + (f" (åŸå§‹: {seed})" if seed != normalized_seed else ""),
                "",
                "ğŸ’¡ æ•…éšœæ’é™¤æ­¥éª¤:",
                "   1. æ£€æŸ¥æ‰€æœ‰èŠ‚ç‚¹è¿æ¥æ˜¯å¦æ­£ç¡®",
                "   2. ç¡®ä¿ä¸Šæ¸¸èŠ‚ç‚¹å·²å®Œå…¨æ‰§è¡Œ",
                "   3. éªŒè¯API Keyå’Œç½‘ç»œè¿æ¥",
                "   4. æŸ¥çœ‹ComfyUIæ§åˆ¶å°è·å–è¯¦ç»†æ—¥å¿—"
            ])
            
            error_text = "\n".join(error_text_parts)
            
            # æ‰“å°è¯¦ç»†é”™è¯¯ä¿¡æ¯åˆ°æ§åˆ¶å°ä»¥ä¾¿è°ƒè¯•
            print(f"SeedreamImageGenerate é”™è¯¯è¯¦æƒ…:")
            print(f"  é”™è¯¯ç±»å‹: {type(e).__name__}")
            print(f"  é”™è¯¯ä¿¡æ¯: {error_msg}")
            print(f"  image1 ç±»å‹: {type(image1) if 'image1' in locals() else 'undefined'}")
            if 'image1' in locals() and image1 is not None:
                print(f"  image1 å½¢çŠ¶: {getattr(image1, 'shape', 'N/A')}")
            
            return ([self.pil_to_tensor(error_img)], error_text)

# Node mappings for ComfyUI
NODE_CLASS_MAPPINGS = {
    "SeedreamImageGenerate": SeedreamImageGenerate
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "SeedreamImageGenerate": "Seedream Image Generate"
}
